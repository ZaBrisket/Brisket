<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Web Scraper (Production Ready)</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet"/>
  <style>
    body { font-family: 'Inter', sans-serif; }
    .spinner { border:4px solid rgba(255,255,255,.3); border-radius:50%; border-top:4px solid #3498db; width:40px; height:40px; animation:spin 1s linear infinite; }
    @keyframes spin { 0% { transform:rotate(0deg) } 100% { transform:rotate(360deg) } }
    pre { white-space: pre-wrap; word-break: break-word; }
    input[type="file"] { display:none; }
    .custom-file-upload { border:1px solid #4a5568; display:inline-block; padding:8px 12px; cursor:pointer; background-color:#2d3748; color:#e2e8f0; border-radius:.5rem; text-align:center; transition:background-color .3s; }
    .custom-file-upload:hover { background-color:#4a5568; }
    .tab-button { transition: background-color .3s, color .3s; }
    .tab-button.active { background-color:#4A5568; color:#E2E8F0; }
    .tab-button:not(.active) { background-color:#2D3748; color:#A0AEC0; }
  </style>
</head>
<body class="bg-gray-900 text-gray-200 flex items-center justify-center min-h-screen p-4">

  <div class="w-full max-w-4xl bg-gray-800 rounded-2xl shadow-2xl p-6 md:p-10 space-y-6">
    <div class="text-center">
      <h1 class="text-3xl md:text-4xl font-bold text-white">AI Web Scraper</h1>
      <p class="text-gray-400 mt-2">A tool to visually teach an AI to scrape websites.</p>
    </div>

    <div class="flex border border-gray-600 rounded-lg p-1">
      <button id="schemaModeBtn" class="tab-button active w-1/2 rounded-md py-2 font-semibold">Schema Scrape</button>
      <button id="bulkModeBtn" class="tab-button w-1/2 rounded-md py-2 font-semibold">Bulk Scrape</button>
    </div>

    <div id="schemaInputs" class="space-y-4">
      <p class="text-sm text-gray-400 text-center">Teach the AI to find and scrape content from a single, uniform website.</p>
      <input type="url" id="urlInput" placeholder="Enter a single starting URL..." class="w-full bg-gray-700 border border-gray-600 text-white rounded-lg px-4 py-3">
      <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
        <label for="main-page-upload" class="custom-file-upload w-full"><span id="mainPageFileName">ðŸ“· Main Page Screenshot</span></label>
        <input id="main-page-upload" type="file" accept="image/png, image/jpeg, image/webp"/>
        <label for="sub-page-upload" class="custom-file-upload w-full"><span id="subPageFileName">ðŸ“· Sub-Page Screenshot</span></label>
        <input id="sub-page-upload" type="file" accept="image/png, image/jpeg, image/webp"/>
      </div>
      <label for="next-button-upload" class="custom-file-upload w-full"><span id="nextButtonFileName">ðŸ“· "Next Button" Screenshot</span></label>
      <input id="next-button-upload" type="file" accept="image/png, image/jpeg, image/webp"/>
    </div>

    <div id="bulkInputs" class="hidden space-y-4">
      <p class="text-sm text-gray-400 text-center">Paste a list of URLs to quickly scrape all text from each page.</p>
      <textarea id="urlList" rows="8" placeholder="Paste your list of URLs here, one per line..." class="w-full bg-gray-700 border border-gray-600 text-white rounded-lg px-4 py-3"></textarea>
    </div>

    <button id="scrapeBtn" class="w-full bg-blue-600 hover:bg-blue-700 text-white font-semibold rounded-lg px-6 py-3 transition duration-300 shadow-lg flex items-center justify-center">
      Scrape
    </button>

    <div class="bg-gray-900 rounded-lg p-4 min-h-[400px] flex flex-col">
      <div id="statusContainer" class="hidden text-center my-auto">
        <div class="mx-auto"><div class="spinner"></div></div>
        <p id="statusText" class="text-gray-400 mt-3"></p>
      </div>
      <div id="errorBox" class="hidden bg-red-900 border border-red-700 text-red-200 px-4 py-3 rounded-lg text-center">
        <strong class="font-bold">Error:</strong> <span id="errorMessage"></span>
      </div>
      <div id="resultsContainer" class="w-full h-full" style="display:none;">
        <div class="flex justify-between items-center mb-2">
          <span id="resultsTitle" class="text-gray-400 font-mono text-sm">Scraped Data:</span>
          <div class="flex gap-2">
            <button id="copyBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Copy</button>
            <button id="downloadTxtBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Download .txt</button>
            <button id="downloadJsonlBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Download .jsonl</button>
          </div>
        </div>
        <pre class="bg-black rounded-md p-4 w-full h-[400px] overflow-auto text-sm text-green-400 font-mono"><code id="resultsCode"></code></pre>
      </div>
    </div>
  </div>

  <script>
    // --- DOM refs ---
    const schemaModeBtn = document.getElementById('schemaModeBtn');
    const bulkModeBtn = document.getElementById('bulkModeBtn');
    const schemaInputs = document.getElementById('schemaInputs');
    const bulkInputs = document.getElementById('bulkInputs');
    const urlInput = document.getElementById('urlInput');
    const urlList = document.getElementById('urlList');
    const mainPageFileInput = document.getElementById('main-page-upload');
    const subPageFileInput = document.getElementById('sub-page-upload');
    const nextButtonFileInput = document.getElementById('next-button-upload');
    const mainPageFileNameSpan = document.getElementById('mainPageFileName');
    const subPageFileNameSpan = document.getElementById('subPageFileName');
    const nextButtonFileNameSpan = document.getElementById('nextButtonFileName');
    const scrapeBtn = document.getElementById('scrapeBtn');
    const statusContainer = document.getElementById('statusContainer');
    const statusText = document.getElementById('statusText');
    const errorBox = document.getElementById('errorBox');
    const errorMessage = document.getElementById('errorMessage');
    const resultsContainer = document.getElementById('resultsContainer');
    const resultsTitle = document.getElementById('resultsTitle');
    const resultsCode = document.getElementById('resultsCode');
    const copyBtn = document.getElementById('copyBtn');
    const downloadTxtBtn = document.getElementById('downloadTxtBtn');
    const downloadJsonlBtn = document.getElementById('downloadJsonlBtn');

    let currentMode = 'schema';
    let scrapeResults = [];

    // Mode toggle
    schemaModeBtn.addEventListener('click', () => {
      currentMode = 'schema';
      schemaModeBtn.classList.add('active'); bulkModeBtn.classList.remove('active');
      schemaInputs.style.display = 'block'; bulkInputs.style.display = 'none';
    });
    bulkModeBtn.addEventListener('click', () => {
      currentMode = 'bulk';
      bulkModeBtn.classList.add('active'); schemaModeBtn.classList.remove('active');
      bulkInputs.style.display = 'block'; schemaInputs.style.display = 'none';
    });

    // File UI
    mainPageFileInput.addEventListener('change', () => mainPageFileNameSpan.textContent = mainPageFileInput.files.length > 0 ? `âœ… ${mainPageFileInput.files[0].name}` : 'ðŸ“· Main Page Screenshot');
    subPageFileInput.addEventListener('change', () => subPageFileNameSpan.textContent = subPageFileInput.files.length > 0 ? `âœ… ${subPageFileInput.files[0].name}` : 'ðŸ“· Sub-Page Screenshot');
    nextButtonFileInput.addEventListener('change', () => nextButtonFileNameSpan.textContent = nextButtonFileInput.files.length > 0 ? `âœ… ${nextButtonFileInput.files[0].name}` : 'ðŸ“· "Next Button" Screenshot');

    // Utils
    const toBase64 = file => new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => resolve({ data: reader.result.split(',')[1], mimeType: file.type });
      reader.onerror = error => reject(error);
    });
    const delay = ms => new Promise(r => setTimeout(r, ms));
    const validate = {
      url: (urlString) => { try { const u = new URL(urlString); if (!['http:','https:'].includes(u.protocol)) throw 0; return u.href; } catch { throw new Error(`Invalid URL: ${urlString}`); } },
      screenshot: async (file) => { if (!file) throw new Error('Screenshot file is missing.'); if (file.size > 5*1024*1024) throw new Error('File size exceeds 5MB.'); if (!file.type.startsWith('image/')) throw new Error('Please upload an image.'); return file; }
    };
    const showError = msg => { errorMessage.textContent = msg; errorBox.classList.remove('hidden'); };

    // API layer (serverless)
    const api = {
      async fetchUrl(url) {
        const res = await fetch(`/api/fetch-url?url=${encodeURIComponent(url)}`);
        if (!res.ok) { const err = await res.json().catch(()=>({})); throw new Error(err.error || `Server responded ${res.status}`); }
        const { html } = await res.json();
        return html;
      },
      async getSchema(payload) {
        const res = await fetch('/api/get-schema', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });
        if (!res.ok) { const err = await res.json().catch(()=>({})); throw new Error(err.error || `AI server responded ${res.status}`); }
        return await res.json();
      }
    };

    // Main button
    scrapeBtn.addEventListener('click', async () => {
      errorBox.classList.add('hidden');
      resultsContainer.style.display = 'none';
      statusContainer.classList.remove('hidden');
      scrapeBtn.disabled = true; scrapeBtn.classList.add('opacity-50');
      scrapeResults = [];
      resultsCode.textContent = '';

      try {
        if (currentMode === 'schema') await runSchemaScrape();
        else await runBulkScrape();
      } catch (e) {
        console.error(e); showError(`Operation failed. ${e.message}`);
      } finally {
        statusContainer.classList.add('hidden');
        scrapeBtn.disabled = false; scrapeBtn.classList.remove('opacity-50');
      }
    });

    async function runSchemaScrape() {
      resultsTitle.textContent = "Scraped Text Content:";
      const startUrl = validate.url(urlInput.value.trim());
      const [mainPageFile, subPageFile, nextButtonFile] = await Promise.all([
        validate.screenshot(mainPageFileInput.files[0]),
        validate.screenshot(subPageFileInput.files[0]),
        validate.screenshot(nextButtonFileInput.files[0])
      ]);

      statusText.textContent = 'Fetching main page HTML...';
      const mainPageHtml = await api.fetchUrl(startUrl);

      const [mainPageB64, subPageB64, nextButtonB64] = await Promise.all([toBase64(mainPageFile), toBase64(subPageFile), toBase64(nextButtonFile)]);
      statusText.textContent = 'Teaching AI...';
      const { linkSelector, nextButtonText } = await api.getSchema({ mainPageHtml, mainPageB64, subPageB64, nextButtonB64 });

      const parser = new DOMParser();
      const mainDoc = parser.parseFromString(mainPageHtml, 'text/html');
      let preflight = 0; try { preflight = mainDoc.querySelectorAll(linkSelector).length; } catch { preflight = 0; }
      if (preflight === 0) throw new Error(`Pre-flight failed: selector "${linkSelector}" found 0 links.`);

      statusText.textContent = `Pre-flight passed! Found ${preflight} links. Starting crawl...`;
      await delay(500);

      const allLinksToVisit = new Set();
      let currentPageUrl = startUrl;
      let pageCount = 1;
      let currentHtml = mainPageHtml;

      while (currentPageUrl) {
        statusText.textContent = `Finding links on page ${pageCount}...`;
        const doc = parser.parseFromString(currentHtml, 'text/html');

        doc.querySelectorAll(linkSelector).forEach(a => {
          try { allLinksToVisit.add(new URL(a.href, currentPageUrl).href); } catch {}
        });

        const nextCandidate = Array.from(doc.querySelectorAll('a, button'))
          .find(btn => btn.innerText.trim().toLowerCase() === (nextButtonText||'').trim().toLowerCase());
        if (nextCandidate && nextCandidate.href) {
          currentPageUrl = new URL(nextCandidate.href, currentPageUrl).href;
          await delay(250);
          currentHtml = await api.fetchUrl(currentPageUrl);
          pageCount++;
        } else {
          currentPageUrl = null;
        }
      }

      const linksArray = Array.from(allLinksToVisit);
      if (linksArray.length === 0) throw new Error(`Selector "${linkSelector}" did not find any links.`);
      await processUrlsInParallel(linksArray, 'Scraping sub-page');
    }

    async function runBulkScrape() {
      resultsTitle.textContent = "Scraped Text Content:";
      const urls = urlList.value.trim().split('\n').filter(Boolean).map(validate.url);
      if (urls.length === 0) throw new Error('Please paste at least one valid URL.');
      await processUrlsInParallel(urls, 'Scraping URL');
    }

    async function processUrlsInParallel(urls, statusPrefix) {
      let completed = 0;
      const maxConcurrency = 5;
      const urlQueue = urls.map((url, index) => ({ index, url }));

      const processResult = (result) => {
        scrapeResults[result.index] = result;
        completed++;
        statusText.textContent = `${statusPrefix} (${completed}/${urls.length}): Done with ${result.url.substring(0, 50)}...`;
        resultsCode.textContent = scrapeResults
          .filter(Boolean)
          .map(r => `\n\n--- Content from ${r.url} ---\n\n${r.text}`)
          .join('');
      };

      async function worker() {
        while (urlQueue.length > 0) {
          const { index, url } = urlQueue.shift();
          try {
            const html = await api.fetchUrl(url);
            const doc = new DOMParser().parseFromString(html, 'text/html');
            const text = extractCleanText(doc);
            processResult({ index, url, text, success: true });
          } catch (error) {
            processResult({ index, url, text: `FAILED: ${error.message}`, success: false });
          }
          await delay(250);
        }
      }

      const workers = Array(Math.min(maxConcurrency, urls.length)).fill(null).map(worker);
      resultsContainer.style.display = 'block';
      await Promise.all(workers);
      statusText.textContent = `Scrape complete! Processed ${completed} URLs.`;
    }

    function extractCleanText(doc) {
      const contentSelectors = ['main', 'article', '[role="main"]', '.main-content', '.post-body', '#content', '.entry-content'];
      let contentElement;
      for (const selector of contentSelectors) {
        contentElement = doc.querySelector(selector);
        if (contentElement) break;
      }
      const docClone = doc.cloneNode(true);
      docClone.querySelectorAll('script, style, nav, footer, header, aside, form, [role="navigation"], [role="banner"], [role="complementary"]').forEach(el => el.remove());
      let text;
      if (contentElement && contentElement.innerText.trim().length > 200) text = contentElement.innerText.trim();
      else text = docClone.body.innerText.trim();
      return text.replace(/(\r\n|\n|\r){3,}/g, '$1\n');
    }
  </script>
</body>
</html>
