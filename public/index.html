<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>AI Web Scraper (Production Ready)</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com"/>
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin/>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet"/>
  <style>
    body { font-family: 'Inter', sans-serif; }
    .spinner { border:4px solid rgba(255,255,255,.3); border-radius:50%; border-top:4px solid #3498db; width:40px; height:40px; animation:spin 1s linear infinite; }
    @keyframes spin { 0% { transform:rotate(0deg) } 100% { transform:rotate(360deg) } }
    pre { white-space: pre-wrap; word-break: break-word; }
    input[type="file"] { display:none; }
    .custom-file-upload { border:1px solid #4a5568; display:inline-block; padding:8px 12px; cursor:pointer; background-color:#2d3748; color:#e2e8f0; border-radius:.5rem; text-align:center; transition:background-color .3s; }
    .custom-file-upload:hover { background-color:#4a5568; }
    .tab-button { transition: background-color .3s, color .3s; }
    .tab-button.active { background-color:#4A5568; color:#E2E8F0; }
    .tab-button:not(.active) { background-color:#2D3748; color:#A0AEC0; }
  </style>
</head>
<body class="bg-gray-900 text-gray-200 flex items-center justify-center min-h-screen p-4">
  <div class="w-full max-w-4xl bg-gray-800 rounded-2xl shadow-2xl p-6 md:p-10 space-y-6">
    <div class="text-center">
      <h1 class="text-3xl md:text-4xl font-bold text-white">AI Web Scraper</h1>
      <p class="text-gray-400 mt-2">Visually teach an AI to scrape a siteâ€”now safer and more resilient.</p>
    </div>

    <div class="flex border border-gray-600 rounded-lg p-1">
      <button id="schemaModeBtn" class="tab-button active w-1/2 rounded-md py-2 font-semibold">Schema Scrape</button>
      <button id="bulkModeBtn" class="tab-button w-1/2 rounded-md py-2 font-semibold">Bulk Scrape</button>
    </div>

    <!-- Controls: concurrency, delay, run control -->
    <div class="flex flex-col gap-2 bg-gray-900 p-3 rounded-lg border border-gray-700">
      <div class="flex items-center gap-4 text-sm">
        <div class="flex items-center gap-2">
          <label class="text-gray-300">Concurrency</label>
          <input id="conc" type="range" min="1" max="10" value="5"/>
          <span id="concVal" class="w-6 text-right">5</span>
        </div>
        <div class="flex items-center gap-2">
          <label class="text-gray-300">Delay (ms)</label>
          <input id="delayMs" type="number" value="250" class="w-24 bg-gray-700 border border-gray-600 rounded px-2 py-1 text-gray-100"/>
        </div>
        <div class="ml-auto flex gap-2">
          <button id="pauseBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Pause</button>
          <button id="resumeBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Resume</button>
          <button id="stopBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Stop</button>
        </div>
      </div>
      <div id="profileBadge" class="hidden text-xs text-emerald-300">Using saved site profile for this origin.</div>
    </div>

    <div id="schemaInputs" class="space-y-4">
      <p class="text-sm text-gray-400 text-center">Teach the AI to find and scrape content from a single, uniform website.</p>
      <input type="url" id="urlInput" placeholder="Enter a single starting URL..." class="w-full bg-gray-700 border border-gray-600 text-white rounded-lg px-4 py-3"/>
      <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
        <label for="main-page-upload" class="custom-file-upload w-full"><span id="mainPageFileName">ðŸ“· Main Page Screenshot</span></label>
        <input id="main-page-upload" type="file" accept="image/png, image/jpeg, image/webp"/>
        <label for="sub-page-upload" class="custom-file-upload w-full"><span id="subPageFileName">ðŸ“· Sub-Page Screenshot</span></label>
        <input id="sub-page-upload" type="file" accept="image/png, image/jpeg, image/webp"/>
      </div>
      <label for="next-button-upload" class="custom-file-upload w-full"><span id="nextButtonFileName">ðŸ“· "Next Button" Screenshot</span></label>
      <input id="next-button-upload" type="file" accept="image/png, image/jpeg, image/webp"/>
    </div>

    <div id="bulkInputs" class="hidden space-y-4">
      <p class="text-sm text-gray-400 text-center">Paste a list of URLs to quickly scrape all text from each page.</p>
      <textarea id="urlList" rows="8" placeholder="Paste your list of URLs here, one per line..." class="w-full bg-gray-700 border border-gray-600 text-white rounded-lg px-4 py-3"></textarea>
    </div>

    <button id="scrapeBtn" class="w-full bg-blue-600 hover:bg-blue-700 text-white font-semibold rounded-lg px-6 py-3 transition duration-300 shadow-lg flex items-center justify-center">
      Scrape
    </button>

    <div class="bg-gray-900 rounded-lg p-4 min-h-[400px] flex flex-col">
      <div id="statusContainer" class="hidden text-center my-auto">
        <div class="mx-auto"><div class="spinner"></div></div>
        <p id="statusText" class="text-gray-400 mt-3"></p>
      </div>
      <div id="errorBox" class="hidden bg-red-900 border border-red-700 text-red-200 px-4 py-3 rounded-lg text-center">
        <strong class="font-bold">Error:</strong> <span id="errorMessage"></span>
      </div>
      <div id="resultsContainer" class="w-full h-full" style="display:none;">
        <div class="flex justify-between items-center mb-2">
          <span id="resultsTitle" class="text-gray-400 font-mono text-sm">Scraped Data:</span>
          <div class="flex gap-2">
            <button id="copyBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Copy</button>
            <button id="downloadTxtBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Download .txt</button>
            <button id="downloadJsonlBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Download .jsonl</button>
            <button id="downloadCsvBtn" class="bg-gray-700 hover:bg-gray-600 text-gray-300 text-xs font-semibold rounded-md px-3 py-1">Download .csv</button>
          </div>
        </div>
        <pre class="bg-black rounded-md p-4 w-full h-[400px] overflow-auto text-sm text-green-400 font-mono"><code id="resultsCode"></code></pre>
      </div>
    </div>
  </div>

  <script>
    // --- Elements ---
    const schemaModeBtn = document.getElementById('schemaModeBtn');
    const bulkModeBtn = document.getElementById('bulkModeBtn');
    const schemaInputs = document.getElementById('schemaInputs');
    const bulkInputs = document.getElementById('bulkInputs');
    const urlInput = document.getElementById('urlInput');
    const urlList = document.getElementById('urlList');
    const mainPageFileInput = document.getElementById('main-page-upload');
    const subPageFileInput = document.getElementById('sub-page-upload');
    const nextButtonFileInput = document.getElementById('next-button-upload');
    const mainPageFileNameSpan = document.getElementById('mainPageFileName');
    const subPageFileNameSpan = document.getElementById('subPageFileName');
    const nextButtonFileNameSpan = document.getElementById('nextButtonFileName');
    const scrapeBtn = document.getElementById('scrapeBtn');
    const statusContainer = document.getElementById('statusContainer');
    const statusText = document.getElementById('statusText');
    const errorBox = document.getElementById('errorBox');
    const errorMessage = document.getElementById('errorMessage');
    const resultsContainer = document.getElementById('resultsContainer');
    const resultsTitle = document.getElementById('resultsTitle');
    const resultsCode = document.getElementById('resultsCode');
    const copyBtn = document.getElementById('copyBtn');
    const downloadTxtBtn = document.getElementById('downloadTxtBtn');
    const downloadJsonlBtn = document.getElementById('downloadJsonlBtn');
    const downloadCsvBtn = document.getElementById('downloadCsvBtn');
    const concInput = document.getElementById('conc');
    const concVal = document.getElementById('concVal');
    const delayInput = document.getElementById('delayMs');
    const pauseBtn = document.getElementById('pauseBtn');
    const resumeBtn = document.getElementById('resumeBtn');
    const stopBtn = document.getElementById('stopBtn');
    const profileBadge = document.getElementById('profileBadge');

    let currentMode = 'schema';
    let RESULTS = [];  // [{url,title,text,ok,error,description,author,published_at}]
    let RUN_CTRL = { paused: false, aborted: false };

    // --- Mode switching ---
    schemaModeBtn.addEventListener('click', () => {
      currentMode = 'schema';
      schemaModeBtn.classList.add('active'); bulkModeBtn.classList.remove('active');
      schemaInputs.style.display = 'block'; bulkInputs.style.display = 'none';
    });
    bulkModeBtn.addEventListener('click', () => {
      currentMode = 'bulk';
      bulkModeBtn.classList.add('active'); schemaModeBtn.classList.remove('active');
      bulkInputs.style.display = 'block'; schemaInputs.style.display = 'none';
    });

    // --- File input UI ---
    mainPageFileInput.addEventListener('change', () => mainPageFileNameSpan.textContent = mainPageFileInput.files.length > 0 ? `âœ… ${mainPageFileInput.files[0].name}` : 'ðŸ“· Main Page Screenshot');
    subPageFileInput.addEventListener('change', () => subPageFileNameSpan.textContent = subPageFileInput.files.length > 0 ? `âœ… ${subPageFileInput.files[0].name}` : 'ðŸ“· Sub-Page Screenshot');
    nextButtonFileInput.addEventListener('change', () => nextButtonFileNameSpan.textContent = nextButtonFileInput.files.length > 0 ? `âœ… ${nextButtonFileInput.files[0].name}` : 'ðŸ“· "Next Button" Screenshot');

    // --- Controls wiring ---
    concInput.addEventListener('input', () => concVal.textContent = concInput.value);
    pauseBtn.addEventListener('click', () => RUN_CTRL.paused = true);
    resumeBtn.addEventListener('click', () => RUN_CTRL.paused = false);
    stopBtn.addEventListener('click', () => RUN_CTRL.aborted = true);

    // --- Utils ---
    const toBase64 = file => new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => resolve({ data: reader.result.split(',')[1], mimeType: file.type });
      reader.onerror = error => reject(error);
    });
    const delay = ms => new Promise(r => setTimeout(r, ms));
    async function yieldIfPausedOrAborted() {
      while (RUN_CTRL.paused) await delay(150);
      if (RUN_CTRL.aborted) throw new Error('Run aborted by user');
    }
    const validate = {
      url: (urlString) => {
        try {
          const url = new URL(urlString);
          if (!['http:', 'https:'].includes(url.protocol)) throw new Error('Invalid protocol.');
          return url.href;
        } catch {
          throw new Error(`Invalid URL: ${urlString}`);
        }
      },
      screenshot: async (file) => {
        if (!file) throw new Error('Screenshot file is missing.');
        if (file.size > 5 * 1024 * 1024) throw new Error('File size exceeds 5MB limit.');
        if (!file.type.startsWith('image/')) throw new Error('Invalid file type, please upload an image.');
        return file;
      }
    };
    const showError = (message) => { errorMessage.textContent = message; errorBox.classList.remove('hidden'); };

    // --- API layer (talks only to your Functions) ---
    const api = {
      async fetchUrl(url) {
        const res = await fetch(`/api/fetch-url?url=${encodeURIComponent(url)}`);
        if (!res.ok) { const err = await res.json().catch(()=>({})); throw new Error(err.error || `Server responded ${res.status}`); }
        const data = await res.json();
        return data.html;
      },
      async getSchema(payload) {
        const res = await fetch('/api/get-schema', { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });
        if (!res.ok) { const err = await res.json().catch(()=>({})); throw new Error(err.error || `AI server responded ${res.status}`); }
        return await res.json(); // {linkSelector,nextButtonText}
      }
    };

    // --- Site profiles (selector caching) ---
    const SITE_PROFILES_KEY = 'siteProfiles';
    function loadProfiles(){ try { return JSON.parse(localStorage.getItem(SITE_PROFILES_KEY) || '{}'); } catch { return {}; } }
    function saveProfiles(p){ localStorage.setItem(SITE_PROFILES_KEY, JSON.stringify(p)); }

    // --- Pagination & URL helpers ---
    const NEXT_TOKENS = ['next','older','more','load more','weiter','suivant','â€º','Â»','>'];
    const norm = s => (s||'').trim().toLowerCase().replace(/\s+/g,' ');
    function resolveHref(el, baseUrl) {
      const a = el?.closest?.('a') || el?.querySelector?.('a') || el;
      const href = a?.getAttribute?.('href') || a?.href || '';
      try { return href ? new URL(href, baseUrl).href : null; } catch { return null; }
    }
    function findNextLink(doc, baseUrl, hintText='') {
      const relNext = doc.querySelector('a[rel="next"], link[rel="next"]');
      if (relNext) {
        const href = relNext.getAttribute('href') || relNext.href;
        try { return new URL(href, baseUrl).href; } catch { /* ignore */ }
      }
      const hint = norm(hintText);
      const candidates = Array.from(doc.querySelectorAll('a,button'));
      const scored = candidates.map(el => {
        const t = norm(el.textContent || el.innerText || '');
        let score = 0;
        if (hint && t === hint) score += 5;
        if (NEXT_TOKENS.some(tok => t.includes(tok))) score += 3;
        if (el.getAttribute('aria-label')?.toLowerCase().includes('next')) score += 3;
        if ((el.className||'').toLowerCase().includes('next')) score += 2;
        const href = resolveHref(el, baseUrl);
        if (!href) score = -1;
        return { href, score };
      }).filter(x => x.score > 0).sort((a,b)=>b.score-a.score);
      return scored[0]?.href || null;
    }
    function cleanUrl(href) {
      try {
        const u = new URL(href);
        u.hash = '';
        ['utm_source','utm_medium','utm_campaign','utm_term','utm_content','gclid','igshid'].forEach(p => u.searchParams.delete(p));
        return u.href;
      } catch { return href; }
    }

    // --- Readability-like extraction + metadata ---
    function extractMainContent(doc) {
      const docClone = doc.cloneNode(true);
      docClone.querySelectorAll('script, style, nav, footer, header, aside, form, [role="navigation"], [role="banner"], [role="complementary"], noscript, iframe, svg').forEach(el => el.remove());
      const candidates = Array.from(docClone.querySelectorAll('main, article, [role="main"], .main-content, .post, .post-body, .entry, .entry-content, #content, .content, section'));
      const set = new Set(candidates);
      if (docClone.body) set.add(docClone.body);
      function score(el) {
        const text = (el.innerText || '').trim();
        const len = text.length;
        const links = el.querySelectorAll('a').length;
        const nodes = el.querySelectorAll('*').length || 1;
        const linkDensity = Math.min(0.9, links / nodes);
        const pCount = el.querySelectorAll('p').length;
        const hCount = el.querySelectorAll('h1,h2,h3').length;
        return len * (1 - linkDensity) + pCount * 200 + hCount * 100;
      }
      let best = null, bestScore = 0;
      set.forEach(el => { const s = score(el); if (s > bestScore) { bestScore = s; best = el; } });
      let text = (best?.innerText || docClone.body?.innerText || '').trim();
      if (text.length < 200) {
        const meta = doc.querySelector('meta[name="description"], meta[property="og:description"]')?.getAttribute('content');
        if (meta) text = `${doc.title ? doc.title + '\n\n' : ''}${meta}`;
        else text = Array.from(doc.querySelectorAll('p')).map(p => p.innerText.trim()).filter(Boolean).join('\n\n');
      }
      return text.replace(/(\r\n|\n|\r){3,}/g, '\n\n');
    }
    function extractMetadata(doc) {
      const get = sel => doc.querySelector(sel)?.getAttribute('content') || '';
      return {
        title: doc.querySelector('meta[property="og:title"]')?.content || doc.title || '',
        description: get('meta[name="description"]') || get('meta[property="og:description"]') || '',
        author: get('meta[name="author"]') || '',
        published_at: get('meta[property="article:published_time"]') || get('meta[name="date"]') || ''
      };
    }

    // --- Results rendering & downloads ---
    function renderResults() {
      resultsCode.textContent = RESULTS
        .map(r => `\n\n--- Content from ${r.url} ---\n\n${r.text || r.error || ''}`)
        .join('').trim();
    }
    function downloadFile(filename, text) {
      const blob = new Blob([text], { type: 'text/plain;charset=utf-8' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url; a.download = filename; document.body.appendChild(a); a.click(); document.body.removeChild(a); URL.revokeObjectURL(url);
    }
    downloadTxtBtn.addEventListener('click', () => {
      const textContent = RESULTS.map(r => `--- Content from ${r.url} ---\n\n${r.text || r.error || ''}`).join('\n\n');
      downloadFile('scrape_results.txt', textContent);
    });
    downloadJsonlBtn.addEventListener('click', () => {
      const jsonl = RESULTS.map(r => JSON.stringify(r)).join('\n');
      downloadFile('scrape_results.jsonl', jsonl);
    });
    downloadCsvBtn.addEventListener('click', () => {
      const header = ['url','title','ok','text','error','description','author','published_at'];
      const esc = s => `"${(s||'').toString().replace(/"/g,'""')}"`;
      const rows = RESULTS.map(r => [r.url, r.title || '', r.ok === true, r.text || '', r.error || '', r.description || '', r.author || '', r.published_at || ''].map(esc).join(','));
      downloadFile('scrape_results.csv', [header.join(','), ...rows].join('\n'));
    });
    copyBtn.addEventListener('click', async () => {
      try { await navigator.clipboard.writeText(resultsCode.textContent); copyBtn.textContent = 'Copied!'; setTimeout(()=>copyBtn.textContent='Copy', 2000); }
      catch (e) { console.error(e); showError('Failed to copy text to clipboard.'); }
    });

    // --- Main button handler ---
    scrapeBtn.addEventListener('click', async () => {
      errorBox.classList.add('hidden');
      resultsContainer.style.display = 'none';
      statusContainer.classList.remove('hidden');
      scrapeBtn.disabled = true; scrapeBtn.classList.add('opacity-50');
      RESULTS = [];
      resultsCode.textContent = '';
      RUN_CTRL = { paused:false, aborted:false };

      try {
        if (currentMode === 'schema') await runSchemaScrape();
        else await runBulkScrape();
      } catch (error) {
        console.error('Scraping Error:', error);
        showError(`Operation failed. ${error.message}`);
      } finally {
        statusContainer.classList.add('hidden');
        scrapeBtn.disabled = false; scrapeBtn.classList.remove('opacity-50');
      }
    });

    // --- Schema Scrape with profiles, preflight, robust pagination, same-site scope ---
    async function runSchemaScrape() {
      resultsTitle.textContent = "Scraped Text Content:";
      const startUrl = validate.url(urlInput.value.trim());
      const [mainPageFile, subPageFile, nextButtonFile] = await Promise.all([
        validate.screenshot(mainPageFileInput.files[0]),
        validate.screenshot(subPageFileInput.files[0]),
        validate.screenshot(nextButtonFileInput.files[0])
      ]);
      const origin = new URL(startUrl).origin;

      statusText.textContent = 'Fetching main page HTML...';
      let currentPageUrl = startUrl;
      let currentHtml = await api.fetchUrl(startUrl);

      // Prepare images
      const [mainB64, subB64, nextB64] = await Promise.all([toBase64(mainPageFile), toBase64(subPageFile), toBase64(nextButtonFile)]);

      // Load or teach selector
      const profiles = loadProfiles();
      let linkSelector, nextButtonText;
      if (profiles[origin]) {
        ({ linkSelector, nextButtonText } = profiles[origin]);
        profileBadge.classList.remove('hidden');
      } else {
        profileBadge.classList.add('hidden');
        statusText.textContent = 'Teaching AI...';
        ({ linkSelector, nextButtonText } = await api.getSchema({ mainPageHtml: currentHtml, mainPageB64: mainB64, subPageB64: subB64, nextButtonB64: nextB64 }));
        profiles[origin] = { linkSelector, nextButtonText, ts: Date.now() };
        saveProfiles(profiles);
      }

      // Preflight
      const parser = new DOMParser();
      let doc = parser.parseFromString(currentHtml, 'text/html');
      let preflightCount = 0;
      try { preflightCount = doc.querySelectorAll(linkSelector).length; }
      catch { preflightCount = 0; }
      if (preflightCount === 0) {
        delete profiles[origin]; saveProfiles(profiles);
        throw new Error(`Pre-flight check failed: selector "${linkSelector}" matched 0 elements on the main page.`);
      }
      statusText.textContent = `Pre-flight passed (${preflightCount} candidates). Starting crawl...`;
      await delay(800);

      const startOrigin = new URL(startUrl).origin;
      const allLinksToVisit = new Set();
      let pageCount = 1;
      let baselineCount = preflightCount;
      let driftStrikes = 0;

      while (currentPageUrl) {
        await yieldIfPausedOrAborted();
        statusText.textContent = `Finding links on page ${pageCount}...`;

        doc = parser.parseFromString(currentHtml, 'text/html');
        // Collect same-origin, normalized links (resolve containers)
        Array.from(doc.querySelectorAll(linkSelector)).forEach(node => {
          const href = resolveHref(node, currentPageUrl);
          if (!href) return;
          const u = new URL(href);
          if (u.origin === startOrigin) allLinksToVisit.add(cleanUrl(u.href));
        });

        // Drift detection: if match count collapses significantly, re-teach once
        let countNow = 0; try { countNow = doc.querySelectorAll(linkSelector).length; } catch { countNow = 0; }
        if (baselineCount && countNow < Math.max(1, Math.floor(baselineCount * 0.2))) {
          driftStrikes++;
          if (driftStrikes >= 2) {
            statusText.textContent = 'Selector drift detected. Re-teaching AI...';
            ({ linkSelector, nextButtonText } = await api.getSchema({ mainPageHtml: currentHtml, mainPageB64: mainB64, subPageB64: subB64, nextButtonB64: nextB64 }));
            profiles[origin] = { linkSelector, nextButtonText, ts: Date.now() };
            saveProfiles(profiles);
            baselineCount = countNow || baselineCount;
            driftStrikes = 0;
          }
        }

        // Robust "Next" detection
        const nextUrl = findNextLink(doc, currentPageUrl, nextButtonText);
        if (nextUrl) {
          await delay(200);
          currentPageUrl = nextUrl;
          currentHtml = await api.fetchUrl(currentPageUrl);
          pageCount++;
        } else {
          currentPageUrl = null;
        }
      }

      const links = Array.from(allLinksToVisit);
      if (links.length === 0) {
        delete profiles[origin]; saveProfiles(profiles);
        throw new Error(`No links discovered with selector "${linkSelector}".`);
      }
      await processUrlsInParallel(links, 'Scraping sub-page');
    }

    // --- Bulk mode ---
    async function runBulkScrape() {
      resultsTitle.textContent = "Scraped Text Content:";
      const urls = urlList.value.trim().split('\n').filter(Boolean).map(validate.url);
      if (urls.length === 0) throw new Error('Please paste at least one valid URL.');
      await processUrlsInParallel(urls, 'Scraping URL');
    }

    // --- Shared parallel processor with politeness controls ---
    async function processUrlsInParallel(urls, statusPrefix) {
      resultsContainer.style.display = 'block';
      const maxConcurrency = +concInput.value || 5;
      const perReqDelay = +delayInput.value || 250;

      let completed = 0;
      const queue = urls.map((url, index) => ({ index, url }));

      async function worker() {
        while (queue.length > 0) {
          await yieldIfPausedOrAborted();
          const { index, url } = queue.shift();
          statusText.textContent = `${statusPrefix} (${completed + 1}/${urls.length}): ${url.substring(0, 80)}...`;
          try {
            const html = await api.fetchUrl(url);
            const doc = new DOMParser().parseFromString(html, 'text/html');
            const text = extractMainContent(doc);
            const meta = extractMetadata(doc);
            RESULTS[index] = { url, title: meta.title, text, ok: true, error: '', description: meta.description, author: meta.author, published_at: meta.published_at };
          } catch (error) {
            RESULTS[index] = { url, title: '', text: '', ok: false, error: String(error.message || error), description: '', author: '', published_at: '' };
          }
          completed++;
          renderResults();
          await delay(perReqDelay);
        }
      }

      const n = Math.min(maxConcurrency, urls.length);
      await Promise.all(Array.from({length:n}, worker));
      statusText.textContent = `Scrape complete! Processed ${completed} URLs.`;
    }
  </script>
</body>
</html>
